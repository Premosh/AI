{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOT99yiGF2aFVbKvqWYTwoo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"glkYJWaYVKbk","executionInfo":{"status":"ok","timestamp":1727102669958,"user_tz":-345,"elapsed":9474,"user":{"displayName":"zorooo senpaiii","userId":"07788119789813583134"}},"outputId":"0b061f64-08ce-4117-94a2-3d853627f9e9"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Package movie_reviews is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Sentence Tokenization:\n","['CSIT is a popular undergraduate program in Nepal that equips students with the skills to excel in the field of computer science and information technology.']\n","Word Tokenization:\n","['CSIT', 'is', 'a', 'popular', 'undergraduate', 'program', 'in', 'Nepal', 'that', 'equips', 'students', 'with', 'the', 'skills', 'to', 'excel', 'in', 'the', 'field', 'of', 'computer', 'science', 'and', 'information', 'technology', '.']\n","Filtered List (without stopwords):\n","['CSIT', 'popular', 'undergraduate', 'program', 'Nepal', 'equips', 'students', 'skills', 'excel', 'field', 'computer', 'science', 'information', 'technology', '.']\n","Sentiment Analysis Scores:\n","{'neg': 0.0, 'neu': 0.549, 'pos': 0.451, 'compound': 0.6249}\n","Named Entities:\n","(S\n","  It/PRP\n","  's/VBZ\n","  a/DT\n","  dangerous/JJ\n","  business/NN\n","  ,/,\n","  (PERSON Frodo/NNP)\n","  ,/,\n","  going/VBG\n","  out/RP\n","  your/PRP$\n","  door/NN\n","  ./.)\n","Frequency Distribution Most Common Words:\n","[(',', 3), ('are', 2), ('the', 2), ('world', 2), ('is', 2), ('.', 2), ('Untrained', 1), ('neural', 1), ('network', 1), ('models', 1), ('much', 1), ('like', 1), ('new-born', 1), ('babies', 1), (':', 1), ('They', 1), ('created', 1), ('ignorant', 1), ('of', 1), ('(', 1)]\n","Accuracy of Classifier: 0.69\n","Classification of New Review: pos\n"]}],"source":["import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","from nltk.corpus import stopwords, movie_reviews\n","from nltk import pos_tag, ne_chunk\n","from nltk import FreqDist\n","import random\n","\n","# Download necessary resources\n","nltk.download('punkt')\n","nltk.download('vader_lexicon')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","nltk.download('movie_reviews')\n","nltk.download('stopwords') # Download the stopwords resource\n","nltk.download('averaged_perceptron_tagger') # Download the averaged_perceptron_tagger resource\n","\n","# Example string\n","example_string = \"CSIT is a popular undergraduate program in Nepal that equips students with the skills to excel in the field of computer science and information technology.\"\n","\n","# Tokenization\n","print(\"Sentence Tokenization:\")\n","print(sent_tokenize(example_string))\n","print(\"Word Tokenization:\")\n","words_in_example = word_tokenize(example_string)\n","print(words_in_example)\n","\n","# Stopword removal\n","stop_words = set(stopwords.words(\"english\"))\n","filtered_list = [word for word in words_in_example if word.casefold() not in stop_words]\n","print(\"Filtered List (without stopwords):\")\n","print(filtered_list)\n","\n","# Sentiment Analysis\n","sia = SentimentIntensityAnalyzer()\n","sentiment_text = \"Python is an awesome programming language.\"\n","print(\"Sentiment Analysis Scores:\")\n","print(sia.polarity_scores(sentiment_text))\n","\n","# Named Entity Recognition (NER)\n","ner_text = \"It's a dangerous business, Frodo, going out your door.\"\n","words_ner = word_tokenize(ner_text)\n","tagged_words = pos_tag(words_ner)\n","named_entities = ne_chunk(tagged_words)\n","print(\"Named Entities:\")\n","print(named_entities)\n","\n","# Frequency Distribution\n","frq_sen = \"\"\"Untrained neural network models are much like new-born babies: They are created ignorant of the world (if considering tabula rasa epistemological theory), and it is only through exposure to the world, i.e. a posteriori knowledge, that their ignorance is slowly revised.\"\"\"\n","words_freq = word_tokenize(frq_sen)\n","frequency_distribution = FreqDist(words_freq)\n","\n","print(\"Frequency Distribution Most Common Words:\")\n","print(frequency_distribution.most_common(20))\n","\n","# Text Classification\n","# Load movie reviews\n","documents = [(list(movie_reviews.words(fileid)), category)\n","             for category in movie_reviews.categories()\n","             for fileid in movie_reviews.fileids(category)]\n","random.shuffle(documents)\n","\n","# Create a feature extractor\n","def extract_features(words):\n","    return {word: True for word in words}\n","\n","# Prepare training data\n","featuresets = [(extract_features(words), category) for (words, category) in documents]\n","train_set, test_set = featuresets[:1500], featuresets[1500:]\n","\n","# Train Naive Bayes classifier\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n","\n","# Evaluate the classifier\n","accuracy = nltk.classify.accuracy(classifier, test_set)\n","print(\"Accuracy of Classifier:\", accuracy)\n","\n","# Classify a new review\n","new_review = \"The movie was fantastic and I loved the characters.\"\n","new_features = extract_features(word_tokenize(new_review))\n","print(\"Classification of New Review:\", classifier.classify(new_features))"]}]}